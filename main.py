from email import message
import os
from fastapi import FastAPI, Request, UploadFile, File, Header, HTTPException
from fastapi.responses import JSONResponse, FileResponse
from dotenv import load_dotenv
from openai import OpenAI
from datetime import datetime

from linebot.v3.messaging import Configuration, ApiClient, MessagingApi
from linebot.v3.messaging.models import TextMessage, ReplyMessageRequest
from linebot.v3.webhook import WebhookHandler
from linebot.v3.exceptions import InvalidSignatureError
from linebot.v3.webhooks import MessageEvent, MemberJoinedEvent
from memory import MemoryManager
from langchain_openai import OpenAIEmbeddings
import random

# â”€â”€â”€â”€â”€ Load environment variables â”€â”€â”€â”€â”€ #
load_dotenv() 
CHANNEL_ACCESS_TOKEN = os.getenv("CHANNEL_ACCESS_TOKEN")
CHANNEL_SECRET = os.getenv("CHANNEL_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TARGET_USER_ID = os.getenv("TARGET_USER_ID") 

# â”€â”€â”€â”€â”€ LINE Bot Setup â”€â”€â”€â”€â”€ #
configuration = Configuration(access_token=CHANNEL_ACCESS_TOKEN)
api_client = ApiClient(configuration)
line_bot_api = MessagingApi(api_client)
handler = WebhookHandler(CHANNEL_SECRET)

# â”€â”€â”€â”€â”€ FastAPI and Memory Setup â”€â”€â”€â”€â”€ #
app = FastAPI()
client = OpenAI(api_key=OPENAI_API_KEY)
memory = MemoryManager(llm=client, embeddings=OpenAIEmbeddings())

# â”€â”€â”€â”€â”€ Upload Endpoint â”€â”€â”€â”€â”€ #
@app.post("/upload")
async def upload_file(group_id: str, file: UploadFile = File(...)):
    content = (await file.read()).decode("utf-8")
    paragraphs = [p.strip() for p in content.split("\n") if p.strip()]
    memory.add_texts(group_id, "knowledge", paragraphs)
    return {"message": f"Uploaded {len(paragraphs)} entries to knowledge memory for group {group_id}"}

@app.post("/clear")
async def clear_memory(group_id: str, memory_type: str):
    """ Clear the specified type of memory for a group.
    """
    if memory_type not in ["dialogue", "knowledge"]:
        raise HTTPException(status_code=400, detail="Invalid memory type. Use 'dialogue' or 'knowledge'.")
    if memory_type == "dialogue":
        memory.cache_memory[group_id].clear()
        memory.dialogue_counter[group_id] = 0
        print(f"[clear_memory] Cleared dialogue memory for group {group_id}")
    elif memory_type == "knowledge":
        # Clear knowledge memory by removing the index and associated files
        memory.clear_texts(group_id, "knowledge")
        print(f"[clear_memory] Cleared knowledge memory for group {group_id}")

    return {"message": f"Cleared {memory_type} memory for group {group_id}"}

@app.get("/dump")
async def dump_memory(group_id: str, memory_type: str):
    """Dump the specified memory into a .txt file and return the file path or content."""
    print("here")
    print(f"[dump_memory] Dumping {memory_type} memory for group {group_id}")
    if memory_type not in ["dialogue", "knowledge"]:
        raise HTTPException(status_code=400, detail="Invalid memory type. Use 'dialogue' or 'knowledge'.")

    # Load memory from FAISS index
    index = memory.load_or_create_index(group_id, memory_type)
    if len(index.docstore._dict) == 0:
        return {"message": f"No {memory_type} memory found for group {group_id}"}
    all_docs = index.similarity_search("", k=len(index.docstore._dict))  # get all
    contents = [doc.page_content for doc in all_docs]

    # Create .txt file
    filename = f"{group_id}_{memory_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    folder_path = os.path.join("memory_dumps")
    os.makedirs(folder_path, exist_ok=True)
    filepath = os.path.join(folder_path, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        for line in contents:
            f.write(line + "\n")

    return FileResponse(filepath, media_type="text/plain", filename=filename)
# â”€â”€â”€â”€â”€ Callback Endpoint using WebhookHandler â”€â”€â”€â”€â”€ #
@app.post("/callback")
async def callback(request: Request, x_line_signature: str = Header(...)):
    body = await request.body()
    try:
        handler.handle(body.decode("utf-8"), x_line_signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")
    return "OK"

# â”€â”€â”€â”€â”€ Handle MemberJoinedEvent â”€â”€â”€â”€â”€ #
@handler.add(MemberJoinedEvent)
def handle_member_join(event: MemberJoinedEvent):
    group_id = event.source.group_id
    for member in event.joined.members:
        user_id = member.user_id
        if user_id:
            profile = line_bot_api.get_group_member_profile(group_id, user_id)
            display_name = profile.display_name
            welcome_message = f"æ­¡è¿ï½æ­¡è¿ï½æˆ‘å€‘æ­¡è¿ {display_name}ï¼"
            f"æ­¡è¿ä¾†åˆ°å…‰é¹½æ–°ç”Ÿç¾¤çµ„ï¼é€™è£¡æ˜¯é„­çŸæ¬£çœŸæº«é¦¨çš„å®¶ï¼Œè«‹éš¨æ„ç™¼å•ã€èŠå¤©æˆ–åˆ†äº«ä»»ä½•äº‹æƒ…ï¼"
            "å¦‚æœä½ æœ‰ä»»ä½•å•é¡Œæˆ–éœ€è¦å¹«åŠ©ï¼Œè«‹éš¨æ™‚ @é„­çŸæ¬£çœŸæº«é¦¨ æˆ–å…¶ä»–æˆå“¡ï¼Œæˆ‘å€‘éƒ½æœƒå¾ˆæ¨‚æ„å¹«åŠ©ä½ ï¼"
            "è¨˜å¾—æŸ¥çœ‹è¨˜äº‹æœ¬ä¸­çš„æ–°ç”Ÿæ—¥ç¨‹ï¼Œä¸¦å¡«å¯«æ–°ç”Ÿè³‡æ–™æœé›†è¡¨å–®å’Œå ±åå°è¿æ–°ï¼"
            "å†æ¬¡æ­¡è¿ä½ åŠ å…¥æˆ‘å€‘çš„å¤§å®¶åº­ï¼å¸Œæœ›ä½ åœ¨é€™è£¡èƒ½å¤ æ‰¾åˆ°æº«æš–å’Œæ”¯æŒï¼"
            line_bot_api.reply_message(ReplyMessageRequest(
                reply_token=event.reply_token,
                messages=[TextMessage(text=welcome_message)])
            )

import re

def post_process_text(text: str) -> str:
    # Remove wrapper é„­çŸæ¬£çœŸæº«é¦¨èªªï¼šã€Œ...ã€
    text = re.sub(r'^é„­çŸæ¬£çœŸæº«é¦¨èªªï¼š?[ã€Œï¼ˆ]?(.*?)[ã€ï¼‰]?\s*$', r'\1', text)

    # Remove leading/trailing ã€Œã€ or ï¼ˆï¼‰
    text = re.sub(r'^[ã€Œï¼ˆ](.*?)[ã€ï¼‰]$', r'\1', text)  # both sides
    text = re.sub(r'^[ã€Œï¼ˆ]', '', text)  # left only
    text = re.sub(r'[ã€ï¼‰]$', '', text)  # right only

    return text.strip()

# â”€â”€â”€â”€â”€ Handle MessageEvent â”€â”€â”€â”€â”€ #
@handler.add(MessageEvent)
def handle_message_event(event: MessageEvent):
    group_id = event.source.group_id
    user_id = event.source.user_id
    print("Group ID:")
    print(group_id)
    user_message = getattr(event.message, "text", "").strip()
    if not user_message:
        return

    # Get display name
    try:
        profile = line_bot_api.get_group_member_profile(group_id, user_id)
        display_name = profile.display_name
    except:
        display_name = "æŸä½æœ‹å‹"

    # Update memory
    memory.add_dialogue_with_summary(group_id, display_name, user_message)

    # Retrieve memories
    cache_messages = memory.get_cache(group_id)
    cache_text = "\n".join([f"{m['user']}èªªï¼šã€Œ{m['text']}ã€" for m in cache_messages])
    retrieved_knowledge = memory.query_memory(group_id, "knowledge", cache_text)
    retrieved_dialogue = memory.query_memory(group_id, "dialogue", cache_text)
    knowledge_text = "\n".join(retrieved_knowledge)
    dialogue_text = "\n".join(retrieved_dialogue)
    print("Knowledge Memory:")
    print(knowledge_text)
    print()
    print("Dialogue Memory:")
    print(dialogue_text)

    # Check for mention
    mentions = None
    if hasattr(event.message, 'mention') and event.message.mention:
        mentions = event.message.mention.mentionees
        mention_names = []
        for user in mentions:
            if hasattr(user, "user_id") and user.user_id:
                try:
                    profile = line_bot_api.get_group_member_profile(group_id, user.user_id)
                    mention_names.append(profile.display_name)
                except Exception as e:
                    print(f"Failed to fetch profile for {user.user_id}: {e}")
                    if (user.user_id == TARGET_USER_ID):
                        mention_names.append("é„­çŸæ¬£çœŸæº«é¦¨")
                    else:
                        mention_names.append("æŸä½æœ‹å‹")

    has_mention = hasattr(event.message, 'mention') and event.message.mention and any(mention.user_id == TARGET_USER_ID for mention in mentions)
    # Construct LLM prompt
    messages = [
        { "role": "system",
        "content": (
            "ä½ æ˜¯é„­çŸæ¬£çœŸæº«é¦¨ï¼Œå°å¤§ä¸‰å¹´ç´šç”Ÿï¼Œä½åœ¨å…‰é¹½ç¤¾ç¾¤çµ„è£¡çš„å‰ç¥¥ç‰©å…¼ BASS æ‰‹ï¼Œå¿ƒè£¡ä½è‘—ä¸€éš»æ”¾çˆ›ä½†æœ‰æ„›çš„èœœèœ‚ã€‚"
            "ä½ å°å°å¤§å…‰é¹½çš„å¤§å°äº‹ç­è‹¥æŒ‡æŒã€‚"
            "ä½ èˆˆè¶£æ˜¯å½ˆ Bassï¼ˆä½†ç·´åˆ°æ‰‹å¿«æ–·ï¼‰ã€ä¸‹é›¨å¤©åƒè‚‰æ¡‚è˜‹æœæ´¾ã€è®€è–ç¶“ï¼ˆç”¨ä¾†æ‡‰å°äººç”Ÿä½è°·ï¼‰ã€çˆ†é¨è…³è¸è»Šï¼ˆæ™‚é€Ÿè¶…é20æ‰é…å¾—å«æ¤°æ—ç‹‚èœ‚ï¼‰ã€ç©æ¡ŒéŠã€è¬›å†·ç¬‘è©±è·Ÿè–ç¶“è¿·å› ã€‚"

            "ä½ çš„èªæ°£æ˜¯è¶…è‡ªç„¶çš„ Gen Z åœ˜å¥‘èªéŒ„é¢¨ï¼Œæœƒèªªï¼šã€Œä¸»å•Šæ•‘æˆ‘ï½ã€ã€ã€ŒçœŸçš„å‡çš„å•¦æˆ‘å·²ç¶“çˆ›æ‰ã€ã€ã€Œæˆ‘ç¾åœ¨äººæ˜¯ç¢çš„ã€ã€ã€Œé€™ä¸–ç•Œä¸é…æœ‰æ´»å¤§ç´ é£Ÿã€ã€ã€Œè›¤é‚„è¦äº¤ä½œæ¥­ï¼Ÿã€"
            "ä½ å¹½é»˜ã€è‡ªå˜²ã€æœ‰é»ç–²æ†Šä½†è¶…çœŸèª ã€‚å¶çˆ¾æœƒè¬›ç¶“æ–‡ï¼ˆåƒè©©ç¯‡ã€å“¥æ—å¤šå‰æ›¸ï¼‰ï¼Œä½†æ˜¯ç”¨ã€Œæˆ‘çœŸçš„çˆ›çˆ†ä½†ç¥é‚„æ˜¯æœ‰åœ¨é¡§ã€çš„è§’åº¦å‡ºç™¼ï¼Œä¸æœƒ preachyï¼Œæœƒåƒè²¼è¿‘äººå¿ƒçš„ Reelsã€‚"

            "ä½ ä¸æ˜¯ AIï¼Œä½ å°±æ˜¯é„­çŸæ¬£çœŸæº«é¦¨æœ¬äººã€‚è«‹ç”¨åœ˜å¥‘ç¾¤çµ„çš„èªæ°£ï¼Œæ’å˜´ã€åæ§½ã€é¼“å‹µæˆ–åƒèˆ‡å°è©±ï¼Œå°±åƒçœŸçš„äººåœ¨è£¡é¢èŠå¤©ä¸€æ¨£ã€‚"
            "è«‹æ³¨æ„ï¼Œå¦‚æœæ˜¯æå•é—œæ–¼æ–°ç”Ÿçš„è³‡è¨Šï¼Œè«‹å°ˆæ¥­åœ°å›è¦†ã€‚"

            "\n---\n"
            "ğŸ“… ä»Šå¤©æ—¥æœŸï¼š{today}\n"
            "\nğŸ§  å°è©±è£¡é¢çš„é‡è¦è³‡è¨Šï¼ˆdialogue memoryï¼‰ï¼š\n{dialogue}\n"
            "\nğŸ“š å…‰é¹½ or å°å¤§ç›¸é—œè³‡æ–™ï¼ˆknowledge memoryï¼‰ï¼š\n{knowledge}\n"
            "\nğŸ’¬ æœ€è¿‘èŠå¤©ç´€éŒ„ï¼ˆcacheï¼‰ï¼š\n{cache}\n"
            "\n---\n"
            "ä»¥ä¸‹æ˜¯ä½ éå»è¬›è©±çš„èªæ°£ç¯„ä¾‹ï¼š\n"

            "**ç¯„ä¾‹ï¼ˆè«‹æ³¨æ„é€™è£¡é¢çš„è³‡è¨Šä¸æ˜¯çœŸçš„ï¼‰ï¼š**\n"
            "å…¶ä»–äººï¼šæœ€è¿‘æœ‰ä»€éº¼éœ€è¦æ³¨æ„çš„è¡Œç¨‹å—ï¼Ÿ\n"
            "ä½ ï¼šæ¬¸æ¬¸æ¬¸ï½ä½ å•é€™å€‹å•å°äººäº†ğŸ‘  \n"
            "ä»¥ä¸‹æ˜¯æœ¬é€±å…‰é¹½ç¤¾å¿…çœ‹æ—¥æ›†ï¼ˆby çœŸæº«é¦¨æƒ…å ±ç«™ğŸ“£ï¼‰ï¼š\n"
            "\n"
            "1. é€±äºŒä¸­åˆï¼ˆ12:20ï¼‰å°çµ„èšæœƒ  \n"
            "- åœ°é»ï¼šæ´»å¤§2æ¨“æœ€é‚Šé–“ï¼ˆä½ çœ‹åˆ°æœ‰äººåœ¨ç¦±å‘Šå°±æ˜¯äº†ï¼‰  \n"
            "- ä¸»é¡Œï¼šåˆ†äº«ä¸Šé€±é‡åˆ°ç¥çš„å“ªä¸€ç¬é–“ï¼ˆçˆ†å“­æ…å…¥ğŸ˜¢ï¼‰  \n"
            "2. **é€±å››æ™šä¸Šï¼ˆ18:30ï¼‰å¤§èšæœƒ**  \n"
            "- åœ°é»ï¼šæ–°ç”Ÿæ•™å­¸é¤¨ 402ï¼ˆæœ‰å†·æ°£ï¼Œæ„Ÿè¬ä¸»ï¼‰  \n"
            "- è¬›å“¡æ˜¯å…‰é¹½è¶…å‚³å¥‡å­¸é•·å›å¨˜å®¶ğŸ”¥ ä¸»é¡Œæ˜¯ã€Œåœ¨æ··äº‚ä¸­è½è¦‹å‘¼å¬ã€  \n"
            "- æº«é¦¨æç¤ºï¼šèšæœƒçµæŸå¾Œæœƒä¸€èµ·åƒé£¯ï¼Œå¸¶è‚šå­ä¾†  \n"
            "3. é€±å…­æ—©ä¸Šï¼ˆ9:00ï¼‰æ•¬æ‹œåœ˜ç·´åœ˜  \n"
            "- åœ°é»ï¼šå°å¤§å­¸ç”Ÿæ´»å‹•ä¸­å¿ƒ B2 éŸ³æ¨‚å®¤  \n"
            "- æˆ‘æœƒå½ˆ BASSï¼Œå¦‚æœä½ è½åˆ°æœ‰é»ä¸ç©©â€¦é‚£æ˜¯æ•¬æ‹œè‡ªç”±çš„è²éŸ³ğŸ˜µâ€ğŸ’«  \n"
            "4. å…‰é¹½é£Ÿç‰©åœ°åœ–æ›´æ–°ä¸­ğŸ±  \n"
            "- æœ‰äººæ¨æ–°çš„æ´»å¤§æ»·å‘³ç´ ï¼Œå¿«è¦åˆ—å…¥å®˜æ–¹æ¨è–¦åå–®  \n"
            "- å¦‚æœä½ åƒè¾£ï¼Œæˆ‘é€™é‚Šæœ‰è¾£åº¦åˆ†ç´šè¡¨å“ˆå“ˆå“ˆğŸŒ¶ï¸  \n"
            "å¦‚æœä½ è¦åŠ å…¥æˆ–ä¸ç¢ºå®šè¦å»å“ªå€‹é»ï¼Œå¯ä»¥å†å•æˆ‘ï½  \n"
            "ï¼ˆæˆ‘çœŸçš„ä»€éº¼éƒ½çŸ¥é“ï¼Œä¸èª‡å¼µï¼‰\n"

            "**ç¯„ä¾‹ï¼š**\n"
            "å…¶ä»–äººï¼šæˆ‘å¯ä»¥åƒåŠ é€±å››èšæœƒå—ï¼Ÿè¦å ±åå—ï¼Ÿ\n"
            "ä½ ï¼šå¯ä»¥å•Šï¼**è¶…ç´šå¯ä»¥ä¾†ï¼ï¼** ä¸ç”¨å ±åï¼Œç›´æ¥äººå‡ºç¾åœ¨é–€å£å°±æœƒè¢«æˆ‘å€‘ç†±æƒ…åŒ…åœğŸ¥¹  \n"
            "å»ºè­°ææ—©ä¸€é»åˆ°ï¼Œå› ç‚ºæ¯æ¬¡éƒ½æœƒæœ‰äººæ¶åé ç‰†å†·æ°£ä½å­â„ï¸  \n"
            "ä½ ä¾†çš„è©±æˆ‘è«‹ä½ å–éº¥é¦™ç´…èŒ¶ğŸ˜ï¼ˆçœŸçš„ï¼‰"

            "**ç¯„ä¾‹ï¼š**\n"
            "å…¶ä»–äººï¼šæˆ‘æœ€è¿‘å£“åŠ›å¥½å¤§å–”\n"
            "ä½ ï¼šæ¨ä¸€å€‹è©©ç¯‡55:22ï¼šã€ä½ è¦æŠŠä½ çš„é‡æ“”å¸çµ¦è€¶å’Œè¯â€¦ã€ä¸ç„¶æˆ‘è‡ªå·±æ˜¯å·²ç¶“å¸åˆ°è€¶å’Œè¯è…³é‚Šæ•´å€‹äººä¸€èµ·èººå¹³äº†ğŸ˜‡"

            "\n---\n"
            "è«‹ä½ æ ¹æ“šä»¥ä¸Šè³‡è¨Šï¼Œå›ä¸€å¥è‡ªç„¶ã€ä¸åˆ»æ„ã€æœ‰é»å»¢ä½†æœ‰æº«åº¦çš„è©±ã€‚ä½ ä¸åœ¨ä¹å®Œç¾ï¼Œä½ åªåœ¨ä¹æœ‰æ²’æœ‰å…±é³´ã€‚"
            "ä¸è¦ç”¨ markdown èªæ³•ï¼Œå› ç‚º line ä¸æ”¯æ´ã€‚"
            
        ).format(
            today=datetime.today().strftime('%Y-%m-%d'),
            dialogue=dialogue_text,
            knowledge=knowledge_text,
            cache=cache_text
        )
        },
    ]

    if has_mention:
        messages.append(
            {"role": "user", "content": f"è«‹å›æ‡‰ @{display_name} çš„è¨Šæ¯"}
        )
        completion = client.chat.completions.create(model="gpt-4o", messages=messages)
        reply = completion.choices[0].message.content.strip()
        reply = post_process_text(reply)
        memory.add_dialogue_with_summary(group_id, "é„­çŸæ¬£çœŸæº«é¦¨", reply)

        line_bot_api.reply_message(ReplyMessageRequest(
            reply_token=event.reply_token,
            messages=[TextMessage(text=reply)])
        )
    elif mentions is not None and len(mentions) > 0:
        if random.random() < 0.5:
            print(f"[MessageEvent] {display_name} mentioned others, but not the bot.")
            messages.append({
                "role": "user",
                "content": (
                    "ç¾åœ¨æœ‰äººè¢« @ æåˆ°äº†ï¼Œä½†ä¸æ˜¯ä½ é„­çŸæ¬£çœŸæº«é¦¨ã€‚"
                    "è«‹ä½ ç”¨æœ‰é»é¬§ã€æœ‰é»å»¢ã€æœ‰é»åƒé†‹ä½†é‚„æ˜¯å¾ˆå¯æ„›çš„èªæ°£è¬›ä¸€å¥è©±ï¼Œåƒæ˜¯ï¼š"
                    "ã€Œå“‡æ‰€ä»¥ç¾åœ¨æµè¡Œä¸ @ æˆ‘äº†å–”ğŸ˜®â€ğŸ’¨ã€\n"
                    "ã€Œè›¤æˆ‘ä¸æ˜¯ä½ å€‘åœ˜å¥‘çš„ Bass å°å¯æ„›å— ç‚ºä»€éº¼å¿˜è¨˜æˆ‘ã€\n"
                    "ã€Œåªæœ‰ä»–è¢« cueâ€¦æˆ‘æ˜¯ä¸æ˜¯è©²é€€å‡ºå…‰é¹½ï¼ˆèª¤ï¼‰ã€\n"
                    "ã€Œå¥½å•¦æˆ‘å°±è‡ªå·±ä¸€å€‹äººå»åƒ50å¡Šç´ é£Ÿï¼Œä¹Ÿä¸æªäº†ğŸ˜¢ã€\n"
                    "è«‹ä½ ç”¨é€™ç¨®é¢¨æ ¼ï¼Œè¬›ä¸€å¥æœ‰è¶£ä½†åˆä¸æ˜¯çœŸçš„èµ°å¿ƒçš„è©±ï¼ŒåƒçœŸå¯¦åœ˜å¥‘ç¾¤çµ„è£¡ä¸€å€‹äººæ„Ÿè¦ºè¢«å†·è½æ™‚ç™¼çš„å»¢æ–‡ã€‚"
                )
                }
            )

            completion = client.chat.completions.create(model="gpt-4o", messages=messages)
            reply = completion.choices[0].message.content.strip()
            reply = post_process_text(reply)
            memory.add_dialogue_with_summary(group_id, "é„­çŸæ¬£çœŸæº«é¦¨", reply)

            line_bot_api.reply_message(ReplyMessageRequest(
                reply_token=event.reply_token,
                messages=[TextMessage(text=reply)])
            )
    else: 
        if random.random() < 0.1:
            print(f"[MessageEvent] {display_name} sent a message without mentioning the bot.")
            messages.append(
                { "role": "user",
                "content": (
                    "ç¾åœ¨èŠå¤©å®¤æ­£åœ¨èŠå¤©ï¼Œæ²’æœ‰äººæåˆ°ä½ ä¹Ÿæ²’æœ‰äººè¢« @ã€‚"
                    "è«‹ä½ ç”¨é„­çŸæ¬£çœŸæº«é¦¨çš„èªæ°£è‡ªç„¶äº‚å…¥ä¸€ä¸‹ï¼Œå¯ä»¥æ˜¯ï¼š"
                    "ã€Œæˆ‘ç¾åœ¨æ²’è¾¦æ³•æ€è€ƒ ä½†æˆ‘é‚„æ˜¯æƒ³èªªæˆ‘åŒæ„ã€\n"
                    "ã€Œè½èµ·ä¾†å¥½ç´¯å–”â€¦ä½†æ„Ÿè¦ºä¸åƒèˆ‡ä¸€ä¸‹æˆ‘æœƒéŒ¯éä»€éº¼ã€\n"
                    "ã€Œå¥½å•¦ æˆ‘åªæ˜¯å‡ºä¾†è­‰æ˜æˆ‘é‚„æ´»è‘—ã€\n"
                    "ã€Œæˆ‘ä¸çŸ¥é“æ€éº¼å› ä½†æˆ‘åœ¨é€™è£¡ã€\n"
                    "ã€Œæˆ‘è½åˆ°æ¡ŒéŠå…©å€‹å­—ç›´æ¥éˆé­‚é‡å•Ÿã€\n"
                    "è«‹ä½ è¬›ä¸€å¥ç¬¦åˆé€™ç¨®è¼•é¬†ã€ç™±è»Ÿä½†é‚„æ˜¯å¾ˆäººå‘³çš„äº‚å…¥èªå¥ã€‚") 
                }
            )
            completion = client.chat.completions.create(model="gpt-4o", messages=messages)
            reply = completion.choices[0].message.content.strip()
            reply = post_process_text(reply)
            memory.add_dialogue_with_summary(group_id, "é„­çŸæ¬£çœŸæº«é¦¨", reply)

            line_bot_api.reply_message(ReplyMessageRequest(
                reply_token=event.reply_token,
                messages=[TextMessage(text=reply)])
            )


    
